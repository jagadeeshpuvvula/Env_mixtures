---
title: "Correlation plots and summary tables"
author: "Jagadeesh Puvvula"
date: "2023-02-20"
output:
  pdf_document: default
  html_document:
    df_print: paged
---


```{r, echo=FALSE, message=FALSE}
library(pacman)
pacman::p_load(tidyverse, reshape2, kableExtra)
path <- "E:/BBK17/pj/data_2023apr/obs_w_outcome/"
res<- "E:/BBK17/pj/data_2023apr/results/iq_paper/"
```


#dat for IQ paper plots
```{r}
dat <- read_csv(paste0(path, "wppsi_f_analy.csv")) |> drop_na() |>
  filter( cohort == "1" | cohort == "2" ) |> # 1- for HOME
  mutate_if(is.numeric, round, 4) |>
  clean_names() |>
  rename(sigma_DEHP=dehp, di_Ethyl_OP=op_de, di_Methyl_OP=op_dm, city=center)|>
  rename_at(vars(4:33), toupper) |>
  mutate(cohort = ifelse(cohort == "1", "HOME", "MIREC")) |>
  select(c(cohort, PB, HG, DMA, 
           DDE, PBDE47, PCB118, PCB138, PCB153, PCB180,
           PFHXS, PFOA, PFOS, 
           BCETP, BDCPP, DBUP, DPHP, 
           B_PB, M_PB, P_PB,
           TCS, BPA, 
           MBP, MBZP, MCPP, SIGMA_DEHP, MEP, MIBP,
           DI_ETHYL_OP, DI_METHYL_OP)) |>
  mutate(PB = if_else(cohort == "HOME", PB * 10, PB))
```

correlation
```{r, echo=FALSE, message=FALSE, fig.height=10, fig.width=6.5, dpi=300}
dat_cor<- dat |> select(-c(cohort))

cormat <- round(x=cor(dat_cor, method = "spearman", use = "complete.obs"), digits = 2) |>
  melt() |> 
  clean_names()

ggplot(cormat, aes(x = var2, y = var1, fill = value)) + #, label = value
  geom_tile(color = "white") +
  #geom_text(color = "black", size = 3, vjust = 1) +
  scale_fill_gradient2(low = "red", high = "blue", mid = "white",
                       midpoint = 0,
                       limit = c(-1, 1), space = "Lab",
                       name = "Spearman Correlation | HOME & MIREC [n=617]") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 11, hjust = 1),
        axis.text.y = element_text(angle = 0, vjust = 0.5, size = 11, hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "bottom", legend.box = "horizontal") +
  coord_fixed() +
  # add vertical and horizontal lines to separate variable groups
  geom_vline(xintercept = c(0, 3.5, 9.5, 12.5,  16.5, 19.5, 21.5, 27.5, 29.5), color = "black", size=1.25) +
  geom_hline(yintercept = c(0, 3.5, 9.5, 12.5, 16.5, 19.5, 21.5, 27.5, 29.5), color = "black", size=1.25) 


ggsave(paste0(res, "combined_corrplt.tiff"),
       width=10, height= 8, dpi=300)
```


data summary
```{r, echo=FALSE, message=FALSE, fig.height=10, fig.width=6.5, dpi=300}
####### CONVERT DATA TO LONG FORMAT

dat <- read_csv(paste0(path, "wppsi_f_analy.csv")) |> drop_na() |>
  filter( cohort == "1" | cohort == "2" ) |> # 1- for HOME
  mutate_if(is.numeric, round, 4) |>
  clean_names() |>
  rename(sigma_DEHP=dehp, di_Ethyl_OP=op_de, di_Methyl_OP=op_dm, city=center)|>
  rename_at(vars(4:33), toupper) |>
  mutate(cohort = ifelse(cohort == "1", "HOME", "MIREC")) |>
  mutate(PB = if_else(cohort == "HOME", PB * 10, PB)) |>
  select(-c(1,3, 34:36, 42)) |>
  pivot_longer(!cohort, names_to = "measure", values_to = "value")


######## Exposure data summary ####################
geomean <- function(x, na.rm = T, trim = 0, ...) 
  { exp(mean(log(x, ...), na.rm = na.rm, trim = trim, ...)) }

geosd <- function(x, na.rm = T, ...)
  { exp(sd(log(x, ...), na.rm = na.rm, ...)) }

dat_summ<- dat |> 
    group_by(measure, cohort) |>
    summarise(geometric_mean = geomean(value), geometric_SD = geosd(value),
              arithmatic_mean=mean((value), na.rm=T), arithmatic_std=sd((value), na.rm = T),
              median = median((value), na.rm = T), q25 = quantile(value, .25, na.rm=T),
              q75 = quantile(value, .75, na.rm=T)) |>
    mutate_if(is.numeric, round, 3)

kable(dat_summ, longtable=T, booktabs=T, caption = "") |>
  kable_styling(latex_options = c("repeat_header"))


write_csv(dat_summ, paste0(res, "summary_table.csv"))
```

#for paper exploring categorical variables
```{r}
#count by category
dat_cat <- read_csv(paste0(path, "wppsi_f_analy.csv")) |> 
  drop_na() |>
  filter( cohort == "1" | cohort == "2" ) |> # 1- for HOME
  clean_names() |>
  select(c(2, 34:36, 42)) |>
  mutate_all(as.factor)

#count and pct
dat_cat |>
  group_by(cohort, edu3) |>
  summarise(
    count = n() ) |>
  ungroup() |>
  group_by(cohort) |>
  mutate(
    percent = (count / sum(count)) * 100 )


```





