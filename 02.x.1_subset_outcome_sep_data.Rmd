---
title: "02..x.1"
author: "Jagadeesh Puvvula"
date: "2023-04-12"
output: pdf_document
---

```{r}
library(pacman)
pacman::p_load(tidyverse, janitor, naniar, SuperLearner, caret)
path <- "E:/BBK17/pj/data_2023apr/obs_w_outcome/"
```

```{r}
dat<- read_csv(paste0(path, "home_mirec_w_out.csv")) |>
  select(subject_id, cohort, center, 
         pb, hg, dma, 
         dde, pbde47, pcb153, pcb118, pcb138, pcb153, pcb180, 
         pfhxs, pfoa, pfos, 
         bcetp, bdcpp, dbup, dphp, 
         tcs, bpa, 
         mbp, mbzp, mcpp, dehp, mep, mibp, 
         op_de, op_dm,
         b_pb, m_pb, p_pb,
         cotinine, sex, race, parity_n, mom_age, home_score_total, gest_age, b_wght, b_length, edu3, 
         wppsi_fsiq, wppsi_viq, wppsi_piq,
         basc_ext, basc_inz, basc_bsi, brief_wm, brief_po)

write_csv(dat, paste0(path, "home_mirec_w_out.csv"))
```

#subset for WPPSI outcomes
```{r}
#dropped basc brief
wppsi_dat<- dat |>
  select(-c(46:50))

#all outcomes available for 847
wppsi_df<-wppsi_dat |>
  filter(complete.cases(across(43:45)))

#data version that contain missing values for MIREC covariates
write_csv(wppsi_df, paste0(path, "wppsi_w_miss_covar.csv"))
```

#missing covariates summary
```{r}

show_missing_summary <- function(df) {
  # Create a dataframe with the count of missing values for each variable
  missing_counts <- df %>% 
    summarise_all(~ sum(is.na(.))) %>% 
    gather(variable, missing_count)
  
  # Filter out variables with no missing values
  missing_counts <- missing_counts %>% 
    filter(missing_count > 0)
  
  # Calculate the percent of missing values for each variable
  missing_percents <- df %>% 
    summarise_all(~ mean(is.na(.))) %>% 
    gather(variable, missing_percent)
  
  # Merge the count and percent dataframes
  missing_summary <- left_join(missing_counts, missing_percents, by = "variable")
  
  # Print the summary table
  missing_summary %>% 
    mutate(missing_percent = scales::percent(missing_percent)) %>% 
    arrange(desc(missing_count))
}


x<- show_missing_summary(wppsi_df[34:42])
```

################################################################################
################################################################################

#work on missing MIREC covariates
```{r}
original<- read_csv(paste0(path, "wppsi_w_miss_covar.csv")) |>
  mutate(sex=if_else(sex=="Male", 1, 2),
         race= if_else(race=="White", 1, 2),
         subject_id=as.factor(subject_id))

dat_pred<- read_csv(paste0(path, "wppsi_w_miss_covar.csv")) |>
  mutate(sex=if_else(sex=="Male", 1, 2),
         race= if_else(race=="white", 1, 2)) |>
  filter(cohort=="2")

```

################################################################################
################################################################################

#Set variable that need to be imputed
```{r}
pred_var<- "gest_age"
```


# impute missing covars from MIREC
```{r}
#repeat this process each time for imputing using super learner
impute_missing <- function(data, var_name) {
  
  # Impute missing values with median, except for the variable mentioned
  for (col in names(data)) {
    if (col != var_name && any(is.na(data[[col]]))) {
      data[[col]][is.na(data[[col]])] <- median(data[[col]], na.rm = TRUE)
    }
  }
  
  return(data)
}

# impute missing values for b_length
dat_pred_v1 <- impute_missing(dat_pred, {{pred_var}})

```

```{r}
#filter unknown data for predictions
pred_set <- dat_pred_v1 %>%
  filter(is.na(dat_pred_v1[[pred_var]])) %>%
  select(-c(2:3))


#for training the prediction model
dat_n <- dat_pred_v1 |> drop_na() |>
  select(-c(1:3))

set.seed(123, "L'Ecuyer-CMRG")
indx<- sample(nrow(dat_n), round(0.75*nrow(dat_n)))
train<- dat_n[indx,]
test<- dat_n[-indx,]

y_train<- train[[pred_var]]
x_train<- train[, -which(colnames(train) == pred_var)]

x_test <- as.matrix(test[, -which(colnames(test) == pred_var)])
y_test <- as.matrix(test[[pred_var]])

#model object
sl.obj2<- SuperLearner(y_train, x_train, family = gaussian(), 
                       SL.library = c("SL.mean", "SL.xgboost", "SL.gbm"))
#model validation to get MSE
validation<- predict(sl.obj2, test[, -which(colnames(test) == pred_var)])

# Print the mean squared error
print(paste("Mean Squared Error:", mean((validation$pred - test[[pred_var]])^2)))

# PREDICTING UNKNOWN 
generate_x <- function(sl.obj, pred_set, id_col, pred_var, rounding = 1){
  
  # predict variable using SuperLearner and impute
  imputed <- as.data.frame(predict.SuperLearner(sl.obj, pred_set[-c(id_col, which(names(pred_set) == pred_var))]))
  
  # create data frame with subject_id and predicted variable
  x <- cbind(subject_id = pred_set[, id_col], as.numeric(imputed$pred))
  
  # set the name of the predicted variable
  colnames(x)[2] <- pred_var
  
  # round the predicted variable to the specified number of digits
  x[[pred_var]] <- round(x[[pred_var]], digits = rounding)
  
  # return the resulting data frame
  return(x)
}

#get predictions: Input - > variable column number being predicted, variable name and rounding
x <- generate_x(sl.obj = sl.obj2, pred_set = pred_set, id_col = 1, 
                pred_var = pred_var, rounding = 1)


#########################################

# replacing missing values 
replace_values <- function(x, original) {
  
  # Convert subject_id in x and original to factors
  x$subject_id <- factor(x$subject_id)
  original$subject_id <- factor(original$subject_id)
  
  # Extract the name of the variable to replace from x
  var_name <- names(x)[2]
  
  # Replace values in original with values from x
  original[[var_name]] <- ifelse(original$subject_id %in% x$subject_id, 
                                  x[[var_name]][match(original$subject_id, x$subject_id)], 
                                  original[[var_name]])
  
  # Return the updated original dataframe
  return(original)
}

#replaces NA values with the predicted values
original <- replace_values(x, original)


```

```{r}
write_csv(original, paste0(path, "wppsi_f_analy.csv"))
```

