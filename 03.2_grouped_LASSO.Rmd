---
title: "03.2_grouped_LASSO"
author: "Jagadeesh Puvvula"
date: "2023-02-21"
output: pdf_document
---
Below models adjusted for cotinine, home_score, gestational-age
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(janitor)
```

```{r, echo=FALSE, message=FALSE}
dat<- read_csv("E:/BBK17/pj/wppsi_exp_out_comb/wppsi_fin.csv") |>
  mutate_if(is.numeric, round, 4) |>
  drop_na() |>
  clean_names() |>
  mutate(sex_nu=if_else(sex=="Male", 1,2),
         race_nu=if_else(race_bin=="white",1,2))|>
  rename(Pb=pbsg, Hg=hgsg, DMA=dma_sg, DDE= dde_lp, PBDE_47 = pbde47_lp,
         PCB_118=pcb118_lp, PCB_138=pcb138_lp, PCB_153=pcb153_lp,
         PCB_180=pcb180_lp, PFHxS=pf_hx_spl, PFOA=pfoapl, PFOS=pfospl,
         BCEtP=bcetp_sg, BDCPP=bdcpp_sg, DBuP=dbup_sg, DPhP=dphp_sg,
         TCS=tcs_sg, BPA=bpa_sg, MBP=mbp_sg, MBZP=mbzp_sg, MCPP=mcpp_sg,
         sigma_DEHP=dehp, MEP=mep_sg, MIBP=mibp_sg, di_Ethyl_OP=op_de,
         di_Methyl_OP=op_dm, B_PB=b_pb, M_PB=m_pb, P_PB=p_pb) |>
  select(Pb, Hg, DMA, DDE, PBDE_47, PCB_118, PCB_138, PCB_153, PCB_180,
          PFHxS, PFOA, PFOS, BCEtP, BDCPP, DBuP, DPhP, TCS, BPA, MBP, MBZP,
          MCPP, sigma_DEHP, MEP, MIBP, di_Ethyl_OP, di_Methyl_OP, 
          B_PB, M_PB, P_PB, wppsi_fsiq, wppsi_viq, wppsi_piq, cohort, sex_nu,
          race_nu, cotinine, mom_edu_cat, home_score_total, parity_n, mom_age)

```


```{r, echo=FALSE, message=FALSE}
#Pre-process data
# convert exposures to log scale
dat[c(1:29)] <- log10(dat[c(1:29)])
```

```{r, echo=FALSE}
#data prep
set.seed(2023, "L'Ecuyer-CMRG")

# Define the predictor variables
x <- as.matrix(dat[c(1:29,36,38,40)])
y_fsiq <- as.matrix(dat[, 30])
y_viq <- as.matrix(dat[, 31])
y_piq <- as.matrix(dat[, 32])


# group index for X variables
v.group <- as.factor(c(1,1,1,2,2,2,2,2,2,3,3,3,
                         4,4,4,4,5,5,6,6,6,6,6,6,
                         7,7,8,8,8,0,0,0))
num.group<- as.integer(c(rep(1,times=3), rep(2,times=6), rep(3, times=3),
                         rep(4,times=4), rep(5, times=2), rep(6,times=6),
                         rep(7,times=2), rep(8, times=3), rep(9,times=3)))

labs<- c("metals","POPs", "PFAS", "OPFR", "TCS & BPA", "Phthalates", 
         "OP Pest", "Parabens", "covar")
```

=================================================================================
#Group LASSO using grpreg library 
#combination of coordinate descent optimization and local approximation of penalty functions
#variables can enter either by having strong signal or member of a group with a strong collective signal
#uses convex penalty
#Group LASSO - grpreg - FSIQ


```{r, echo=FALSE, message=FALSE,fig.height=10, fig.width=10, dpi=300}
library(grpreg)

cv_lasso_fsiq <- cv.grpreg(x, y_fsiq, v.group, 
                        penalty = "grLasso", seed = 2023,
                        n.lambda = 200, max.iter = 20000)

plot(cv_lasso_fsiq)

#Find the lambda that results in the smallest CV error
best_lasso_fsiq <- cv_lasso_fsiq$lambda.min

####################################################################
####################################################################
# extract lambda within 1 std error with the lowest validation error
#Match below value with cve and pick corresponding lambda as lambda_1se
cv_ext<- cbind(cv_fit$cve, cv_fit$lambda) |> as.data.frame()
cve_lambda<- min(cv_fit$cve) + sd(cv_fit$cve)/sqrt(100)

lambda_1se_func <- function(df, cve_lambda) {
  # Find the row in the dataframe where the V1 value is closest to cve_lambda
  closest_row <- df[which.min(abs(df$V1 - cve_lambda)),]
  
  # Return the corresponding V2 value
  return(closest_row$V2)
}

lambda_1se<- lambda_1se_func(cv_ext, cve_lambda)
####################################################################
####################################################################

#Fit model with cross-validated lambda
fit_lasso_fsiq <- grpreg(x, y_fsiq, v.group, penalty = "grLasso", 
                         lambda = lambda_1se)

#Look at coefficients from model with best lambda
fit_lasso_fsiq$beta

##prediction and MSE using train dataset
grlasso.pred.fsiq <-  predict(fit_lasso_fsiq, x)
grlasso_MSE_fsiq <-  mean((grlasso.pred.fsiq - y_fsiq)^2)
grlasso_MSE_fsiq

lasso_beta_fsiq <- as_tibble(fit_lasso_fsiq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_fsiq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8", "0")) |>  
  ggplot(aes(x = variable, y = round(beta, 2))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-FSIQ",
       y = "Beta Coefficient", x = "Variable")
```






=================================================================================
#Group LASSO - grpreg - VIQ

```{r, echo=FALSE, fig.height=10, fig.width=10, dpi=300}

cv_lasso_viq <- cv.grpreg(x, y_viq, v.group, 
                        penalty = "grLasso", seed = 123,
                        n.lambda = 200, max.iter = 20000)
plot(cv_lasso_viq)

#Find the lambda that results in the smallest CV error
best_lasso_viq <- cv_lasso_viq$lambda.min

#Fit model with cross-validated lambda
fit_lasso_viq <- grpreg(x, y_viq, v.group, penalty = "grLasso", 
                        lambda = best_lasso_viq)

#Look at coefficients from model with best lambda
fit_lasso_viq$beta

##prediction and MSE using train dataset
grlasso.pred <-  predict(fit_lasso_viq, x)
grlasso_MSE <-  mean((grlasso.pred - y_viq)^2)
grlasso_MSE

lasso_beta_viq <- as_tibble(fit_lasso_viq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_viq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8", "0")) |>  
  ggplot(aes(x = variable, y = round(beta, 5))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-VIQ",
       y = "Beta Coefficient", x = "Variable")
```





=================================================================================

#Group LASSO - grpreg - FSIQ

```{r, echo=FALSE, fig.height=10, fig.width=10, dpi=300}

cv_lasso_piq <- cv.grpreg(x, y_piq, v.group, 
                        penalty = "grLasso", seed = 123,
                        n.lambda = 200, max.iter = 20000)

plot(cv_lasso_piq)


#Find the lambda that results in the smallest CV error
best_lasso_piq <- cv_lasso_piq$lambda.min

#Fit model with cross-validated lambda
fit_lasso_piq <- grpreg(x, y_piq, v.group, penalty = "grLasso", 
                        lambda = best_lasso_piq)

#Look at coefficients from model with best lambda
fit_lasso_piq$beta

##prediction and MSE using train dataset
grlasso.pred_piq <-  predict(fit_lasso_piq, x)
grlasso_MSE_piq <-  mean((grlasso.pred_piq - y_piq)^2)
grlasso_MSE_piq

lasso_beta_piq <- as_tibble(fit_lasso_piq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_piq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8", "0")) |>  
  ggplot(aes(x = variable, y = round(beta, 5))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-PIQ",
       y = "Beta Coefficient", x = "Variable")
```




=================================================================================

#Group and exclusive LASSO using gglaso and ExclusiveLasso packages: using groupwise-majorization descent
```{r, echo=FALSE, message=FALSE}
library(gglasso)
library(glmnet)
library(ExclusiveLasso)
```
=================================================================================
#FSIQ

```{r, echo=FALSE, message=FALSE, fig.height=10, fig.width=10, dpi=300}
set.seed(2023)

# lasso
la_cv <- cv.glmnet(x=x, y=y_fsiq, family="gaussian", alpha=1, intercept = F, nfolds=5)
x11(); plot(la_cv)
paste(la_cv$lambda.min, la_cv$lambda.1se)
 
# group lasso
gr_cv <- cv.gglasso(x=x, y=y_fsiq, group=num.group, pred.loss="L2", intercept = F, nfolds=10)
x11(); plot(gr_cv)
paste(gr_cv$lambda.min, gr_cv$lambda.1se)
 
# exclusive lasso
ex_cv <- cv.exclusive_lasso(X=x, y=y_fsiq, groups = v.group, intercept = F, nfolds=10)
x11(); plot(ex_cv)
paste(ex_cv$lambda.min, ex_cv$lambda.1se)

#——————————————–
# Model with selected lambda
#——————————————–
 
# lasso
la <- glmnet(x=x, y=y_fsiq, family="gaussian", lambda = la_cv$lambda.1se,
             alpha=1, intercept = F) 

# group lasso
gr <- gglasso(x=x, y=y_fsiq, lambda = gr_cv$lambda.1se+0.1,group = num.group, 
              loss="ls",intercept = F)

# exclusive lasso
ex <- exclusive_lasso(x, y=y_fsiq, lambda = ex_cv$lambda.1se, groups = v.group, 
                      family="gaussian",intercept = F) 

# Results
df.comp.lambda.1se <- data.frame(
    Lasso     = la$beta[,1],
    Group     = gr$beta[,1],
    Exclusive = ex$coef[,1]
)
df.comp.lambda.1se
```





=================================================================================

#VIQ

```{r, echo=FALSE, message=FALSE, fig.height=10, fig.width=10, dpi=300}
set.seed(2023)

# lasso
la_cv <- cv.glmnet(x=x, y=y_viq, family="gaussian", alpha=1, intercept = F, nfolds=5)
x11(); plot(la_cv)
paste(la_cv$lambda.min, la_cv$lambda.1se)

# group lasso
gr_cv <- cv.gglasso(x=x, y=y_viq, group=num.group, pred.loss="L2", intercept = F, nfolds=10)
x11(); plot(gr_cv)
paste(gr_cv$lambda.min, gr_cv$lambda.1se)

# exclusive lasso
ex_cv <- cv.exclusive_lasso(X=x, y=y_viq, groups = v.group, intercept = F, nfolds=10)
x11(); plot(ex_cv)
paste(ex_cv$lambda.min, ex_cv$lambda.1se)

#——————————————–
# Model with selected lambda
#——————————————–

# lasso
la <- glmnet(x=x, y=y_viq, family="gaussian", lambda = la_cv$lambda.1se,
             alpha=1, intercept = F) 

# group lasso
gr <- gglasso(x=x, y=y_viq, lambda = gr_cv$lambda.1se+0.1,group = num.group, 
              loss="ls",intercept = F)

# exclusive lasso
ex <- exclusive_lasso(x, y=y_viq, lambda = ex_cv$lambda.1se, groups = v.group, 
                      family="gaussian",intercept = F) 

# Results
df.comp.lambda.1se <- data.frame(
  Lasso     = la$beta[,1],
  Group     = gr$beta[,1],
  Exclusive = ex$coef[,1]
)
df.comp.lambda.1se
```




=================================================================================

#PIQ

```{r, echo=FALSE, message=FALSE, fig.height=10, fig.width=10, dpi=300}
set.seed(2023)

# lasso
la_cv <- cv.glmnet(x=x, y=y_piq, family="gaussian", alpha=1, intercept = F, nfolds=5)
x11(); plot(la_cv)
paste(la_cv$lambda.min, la_cv$lambda.1se)

# group lasso
gr_cv <- cv.gglasso(x=x, y=y_piq, group=num.group, pred.loss="L2", intercept = F, nfolds=10)
x11(); plot(gr_cv)
paste(gr_cv$lambda.min, gr_cv$lambda.1se)

# exclusive lasso
ex_cv <- cv.exclusive_lasso(X=x, y=y_piq, groups = v.group, intercept = F, nfolds=10)
x11(); plot(ex_cv)
paste(ex_cv$lambda.min, ex_cv$lambda.1se)

#——————————————–
# Model with selected lambda
#——————————————–

# lasso
la <- glmnet(x=x, y=y_piq, family="gaussian", lambda = la_cv$lambda.1se,
             alpha=1, intercept = F) 

# group lasso
gr <- gglasso(x=x, y=y_piq, lambda = gr_cv$lambda.1se+0.1,group = num.group, 
              loss="ls",intercept = F)

# exclusive lasso
ex <- exclusive_lasso(x, y=y_piq, lambda = ex_cv$lambda.1se, groups = v.group, 
                      family="gaussian",intercept = F) 

# Results
df.comp.lambda.1se <- data.frame(
  Lasso     = la$beta[,1],
  Group     = gr$beta[,1],
  Exclusive = ex$coef[,1]
)
df.comp.lambda.1se
```
=================================================================================
