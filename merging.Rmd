---
title: "01_merging"
author: "Puvvula"
date: "2022-09-13"
output: pdf_document
---

```{r}
library(tidyverse)
library(skimr)
library(haven)
library(janitor)
library(naniar)
library(corrplot)
library(reshape2)
```

Filter outcome data by year of child visit
```{r}
################## OUTCOME ###############################
# In wide format
dt_outcome<- read_sas("/Users/jpuvvula/Documents/data/outcomes.sas7bdat")|> 
  filter(Visit == "M36")|>
  rename(subject_id = SubjectID) |>
  clean_names()

#subset for age 3 years with required variables
dat_out<- dt_outcome[c(1,16,17,23,24,61:63)] 
write_csv(dat_out, "/Users/jpuvvula/Documents/data/outcome.csv")

dat<- dat |> 
  pivot_longer(!subject_id, names_to = "analyte", values_to = "conc")
dat$category = "outcome"

write_csv(dat_out, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/outcome_wide.csv")

#236 obs with all values
dt<- dat |> drop_na()

#summary for 3 year outcome
skim(dt)

##subset for age 5 years (193 obs.)
dat<- dt_outcome[c(1:6)] |> 
  filter(Visit == "M60")

#subset for age 7.5-10 years ( obs.)
dat<- dt_outcome[c(1,2,7:15,18:24,28,29,31,34:44,46:55,60:63)] |> 
  filter(Visit == "P3")

#subset for age 7.5-10 years (242 obs.with BRIEF and BASC)
dat<- dt_outcome[c(1,2,18:24,27:29,32:63)] |> 
  filter(Visit == "P4")
```

Missing data viz: Outcome at 3 year
```{r}
gg_miss_var(dat, show_pct = T)

gg_miss_upset(dat, nsets=20, nintersects=NA)
```


```{r}
################# COVARIATES #############################
# In wide format
dt_cov <- read_sas("/Users/jpuvvula/Documents/data/covariates.sas7bdat") |>
  as.data.frame()

dt_cov <- dt_cov[c(1:17,34,50:52,54,55,57,59:64)] 
#convert all character inputs to factors
dt_cov <- as.data.frame(unclass(dt_cov), stringsAsFactors=T)

# count unique subjects
length(unique(dt_cov$SubjectID))

dat<- dat|> rename(subject_id = SubjectID) |>
  pivot_longer(!subject_id, names_to = "analyte", values_to = "conc")
dat$category = "outcome"

write_csv(dat, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/outcome.csv")

dat<- left_join(dt_out, dt_cov, by="SubjectID")

cat<- names(dat[c(2:10,12,14:17,18,20,21,27,29,35,50:52,53,55,56,58,62,64,65)])
dat[cat] <- lapply(dat[cat], factor)

skim(dat)
```

Exposure data
```{r}
#reading SAS data
############### EXPOSURES ####################################

#BLOOD
bl_cd<- read_sas("/Users/jpuvvula/Documents/data/bcd.sas7bdat") |> clean_names()
bl_pb<- read_sas("/Users/jpuvvula/Documents/data/bpb.sas7bdat") |> clean_names()
thg <- read_sas("/Users/jpuvvula/Documents/data/thg.sas7bdat") |> clean_names()

# SERUM
############ OC Pest ###########
#remove observations if flg_lod is NA for OP,OC,PBDE
oc_pest<- read_sas("/Users/jpuvvula/Documents/data/ocpest.sas7bdat") |> 
  clean_names() 

#removing flg_lod = NA
labres<-filter(oc_pest, complete.cases(flg_lod_lp))
#summary stats
dat<- oc_pest |>
  group_by(analyte_grp, analyte_code, visit) |>
  summarise(tested=n(),
            bel_lod= sum(flg_lod_lp)) |>
  mutate(pct_lod= round((bel_lod/tested)*100,2))
####################
pbde<- read_sas("/Users/jpuvvula/Documents/data/pbde.sas7bdat") |> clean_names()

####################
pcb<- read_sas("/Users/jpuvvula/Documents/data/pcb.sas7bdat") |> clean_names()

######################
#pfas and ct doesnt have missing values flagging obs below LOD
pfas<- read_sas("/Users/jpuvvula/Documents/data/pfas.sas7bdat") |> clean_names()
ct <- read_sas("/Users/jpuvvula/Documents/data/ct.sas7bdat") |> clean_names()

# URINE
###########################################################
###########################################################
arse<- read_sas("/Users/jpuvvula/Documents/data/ars_i_cd.sas7bdat") |> clean_names()

arse$visit<-"16W" 

#check duplicates by subject per visit per analyte
arse_dat |> group_by(subject_id, visit) |> filter(n()>1)

###########################################################
###########################################################

opfr<- read_sas("/Users/jpuvvula/Documents/data/fr.sas7bdat") |> clean_names()
pheno<- read_sas("/Users/jpuvvula/Documents/data/phen.sas7bdat") |> clean_names()
bpa<- read_sas("/Users/jpuvvula/Documents/data/phthbpa.sas7bdat") |> clean_names()
pyre<- read_sas("/Users/jpuvvula/Documents/data/pyr.sas7bdat") |> clean_names()
op_pest<- read_sas("/Users/jpuvvula/Documents/data/op.sas7bdat") |> clean_names()
op_pest$flg_lod<- replace_na(op_pest$flg_lod, 1)
```

```{r}
dat<- pyre |>
  group_by(analyte_grp, analyte_code, visit) |>
  summarise(tested=n(),
            bel_lod= sum(flg_lod)) |>
  mutate(pct_lod= round((bel_lod/tested)*100,2))
```

Processing exposure data
```{r}
#For Cotinine only (take values from result or from result machine)
ct$Result <- ifelse(is.na(ct$Result), ct$Result_Machine, ct$Result)

#create average for multiple entries [replacing with average values]
#Use for PFAS and Cotinine only
dt_imp<- pfas |> 
  group_by(SubjectID, Visit, Analyte_Code) |>
  summarise_at(vars("Result"), mean)

#summaries for all variables
dt <- thg [c(1,2,5,6)] |>
  pivot_wider(names_from = c(Analyte_Code),
              values_from = Result)

dt_out <-dt |> 
  dplyr::group_by(Visit) |>
  skim()

write_csv(dt_out, "con.csv")
```

Specific gravity adjustment
```{r}
sg<- read_csv("/Users/jpuvvula/Documents/data/home_16w_imp/creat_sg.csv") |>
  filter(visit=="16W")

dt<- read_csv("/Users/jpuvvula/Documents/data/home_16w_imp/DMA_16w.csv") 

dat<- inner_join(dt,sg, by="subject_id")

med_sg<- median(dat$specific_gravity)
dat<- dat |> 
  mutate(dma_sg = ((dat$result.res*(med_sg-1))/(dat$specific_gravity-1)))

dat<- dat[c(1,2,8)] |> rename(dma = result.res, subject_id = subject_id) |>
  pivot_longer(!subject_id, names_to = "analyte", values_to = "conc")

write_csv(dat, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/dma.csv")

```

wide to long lipid adjusted and whole blood samples
```{r}
dat<- read_csv("/Users/jpuvvula/Documents/data/home_16w_imp/pbde47_16w.csv") 
dat<- dat[c(1,2)] |> rename(pbde47 = result.res) |>
  pivot_longer(!subject_id, names_to = "analyte", values_to = "conc")

write_csv(dat, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/pbde47.csv")
```

Merge all exposures to a csv
```{r}
file_names<- list.files(path= "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/",
                        recursive = T,
                        pattern = "\\.csv$",
                        full.names = T)

dat<- read_csv(file_names)

write_csv(dat, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/home_exp_fin.csv")

######## Exposure data summary ####################
geomean <- function(x, na.rm = T, trim = 0, ...) 
  { exp(mean(log(x, ...), na.rm = na.rm, trim = trim, ...)) }

geosd <- function(x, na.rm = T, ...)
  { exp(sd(log(x, ...), na.rm = na.rm, ...)) }

dat_summ<- dat |> 
  group_by(analyte) |>
  summarise(no_obs= n(),
            geometric_mean = geomean(conc), geometric_SD = geosd(conc),
            arithmatic_mean=mean((conc), na.rm=T), arithmatic_std=sd((conc), na.rm = T),
            median = median((conc), na.rm = T), q25 = quantile(conc, .25, na.rm=T),
            q75 = quantile(conc, .75, na.rm=T)) |>
  mutate_if(is.numeric, round, 3)

write_csv(dat_summ, "/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/exp_fin_summary.csv")
```

Exposure missing data summary

```{r}
dat<- read_csv("/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/home_exp_fin.csv") |>
  pivot_wider(names_from = analyte, values_from = conc)

# variable 18 for DMA
dat_exp<- dat[c(1,3,5,7,9,11,12,14, 16, 20,22, 24, 25, 27, 29, 31, 33, 35, 37, 39, 41, 42:50, 53)] 

dat<- dat |> drop_na()

gg_miss_upset(dat, nsets=5, nintersects=NA)

```

combine exposure and outcome
```{r}
#load outcome
dat_out<- read_csv("/Users/jpuvvula/Documents/data/home_16w_imp/mirec_transf/outcome_wide.csv")

dat_fin<- inner_join(dat, dat_out, by="subject_id") |>
  drop_na()

cormat<- round(x=cor(dat_fin[2:38], method = "spearman", 
                     use= "complete.obs"), digits=2) |>
  melt() |> clean_names()

ggplot(cormat, aes(x=var2, y=var1, fill=value)) +
  geom_tile(color="white")+
  scale_fill_gradient2(low="red", high="blue", mid="white",
                       midpoint=0,
                       limit=c(-1,1), space= "Lab",
                      name="Spearman\nCorrelation")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 12, hjust = 1),
        axis.text.y = element_text(angle = 0, vjust = 1, size = 12, hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank())+
  coord_fixed()

ggsave("/Users/jpuvvula/Documents/data/corplot.tiff",
       width=14, height= 12, dpi=300)
```


