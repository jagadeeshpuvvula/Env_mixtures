---
title: "03.2_grouped_LASSO"
author: "Jagadeesh Puvvula"
date: "2023-02-09"
output: pdf_document
---
Below models adjusted for cotinine, education, parity, home_score, race
```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(janitor)
library(reshape2)
library(grpreg)
```

```{r, echo=FALSE, message=FALSE}
dat<- read_csv("E:/BBK17/pj/wppsi_exp_out_comb/wppsi_fin.csv") |>
  mutate_if(is.numeric, round, 4) |>
  drop_na() |>
  clean_names() |>
  rename(Pb=pbsg, Hg=hgsg, DMA=dma_sg, DDE= dde_lp, PBDE_47 = pbde47_lp,
         PCB_118=pcb118_lp, PCB_138=pcb138_lp, PCB_153=pcb153_lp,
         PCB_180=pcb180_lp, PFHxS=pf_hx_spl, PFOA=pfoapl, PFOS=pfospl,
         BCEtP=bcetp_sg, BDCPP=bdcpp_sg, DBuP=dbup_sg, DPhP=dphp_sg,
         TCS=tcs_sg, BPA=bpa_sg, MBP=mbp_sg, MBZP=mbzp_sg, MCPP=mcpp_sg,
         sigma_DEHP=dehp, MEP=mep_sg, MIBP=mibp_sg, di_Ethyl_OP=op_de,
         di_Methyl_OP=op_dm, B_PB=b_pb, M_PB=m_pb, P_PB=p_pb) |>
  select(Pb, Hg, DMA, DDE, PBDE_47, PCB_118, PCB_138, PCB_153, PCB_180,
          PFHxS, PFOA, PFOS, BCEtP, BDCPP, DBuP, DPhP, TCS, BPA, MBP, MBZP,
          MCPP, sigma_DEHP, MEP, MIBP, di_Ethyl_OP, di_Methyl_OP, 
          B_PB, M_PB, P_PB, wppsi_fsiq, wppsi_viq, wppsi_piq, cohort, city, sex,
          race_bin, cotinine, mom_edu_cat, home_score_total, parity_n, mom_age)

dat<- dat |> 
  mutate(across(all_of(c("cohort", "city", "sex", "race_bin", 
                         "parity_n", "mom_edu_cat")), as.factor))
```

Pre-process data
```{r, echo=FALSE}
# exposure and outcome variables
numeric_vars <- sapply(dat, is.numeric)

# Convert numeric variables to log2 scale
dat[c(5:37)] <- log10(dat[c(5:37)])
```



data prep - WPPSI FSIQ
```{r, echo=FALSE}
set.seed(2023, "L'Ecuyer-CMRG")

# Define the predictor variables
x <- as.matrix(dat[c(5:34,41:44,48)])
y <- as.matrix(dat[, 35])

# group index for X variables
v.group <- as.factor(c(1,1,1,2,2,2,2,2,2,3,3,3,
                         4,4,4,4,5,5,6,6,6,6,6,6,
                         7,7,8,8,8))

gr_lasso_piq<- grpreg(x, y, v.group, penalty="grLasso")
plot(gr_lasso_piq)
```

MODEL -FSIQ
```{r, echo=FALSE, fig.height=10, fig.width=10, dpi=300}
cv_lasso_fsiq <- cv.grpreg(x, y, v.group, 
                        penalty = "grLasso", seed = 2023,
                        n.lambda = 200, max.iter = 20000)


#Find the lambda that results in the smallest CV error
best_lasso_fsiq <- cv_lasso_fsiq$lambda.min

#Fit model with cross-validated lambda
fit_lasso_fsiq <- grpreg(x, y, v.group, penalty = "grLasso", lambda = best_lasso_fsiq)

#Look at coefficients from model with best lambda
fit_lasso_fsiq$beta

##prediction and MSE using train dataset
grlasso.pred.fsiq <-  predict(fit_lasso_fsiq, x)
grlasso_MSE_fsiq <-  mean((grlasso.pred.fsiq - y)^2)
grlasso_MSE_fsiq

lasso_beta_fsiq <- as_tibble(fit_lasso_fsiq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_fsiq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8")) |>  
  ggplot(aes(x = variable, y = round(beta, 5))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-FSIQ",
       y = "Beta Coefficient", x = "Variable")
```

data prep - WPPSI VIQ
```{r, echo=FALSE}
set.seed(123, "L'Ecuyer-CMRG")

# Define the predictor variables
x_viq <- as.matrix(dat[c(5:34,41:44,48)])
y_viq <- as.matrix(dat[, 36])

# group index for X variables
v.group <- as.factor(c(1,1,2,0,1,6,3,1,3,5,5,5,5,5,3,6,6,
                       6,6,6,7,7,7,2,5,8,8,4,4,4,0,0,0,0,0))

gr_lasso<- grpreg(x_viq, y_viq, v.group, penalty="grLasso")
plot(gr_lasso)
```

MODEL -VIQ
```{r, echo=FALSE, fig.height=10, fig.width=10, dpi=300}
cv_lasso_viq <- cv.grpreg(x_viq, y_viq, v.group, 
                        penalty = "grLasso", seed = 123,
                        n.lambda = 200, max.iter = 20000)


#Find the lambda that results in the smallest CV error
best_lasso_viq <- cv_lasso_viq$lambda.min

#Fit model with cross-validated lambda
fit_lasso_viq <- grpreg(x, y, v.group, penalty = "grLasso", lambda = best_lasso_viq)

#Look at coefficients from model with best lambda
fit_lasso_viq$beta

##prediction and MSE using train dataset
grlasso.pred <-  predict(fit_lasso_viq, x)
grlasso_MSE <-  mean((grlasso.pred - y)^2)
grlasso_MSE

lasso_beta_viq <- as_tibble(fit_lasso_viq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_viq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8")) |>  
  ggplot(aes(x = variable, y = round(beta, 5))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-VIQ",
       y = "Beta Coefficient", x = "Variable")
```


data prep - WPPSI PIQ
```{r, echo=FALSE}
set.seed(123, "L'Ecuyer-CMRG")

# Define the predictor variables
x_piq <- as.matrix(dat[c(5:34,41:44,48)])
y_piq <- as.matrix(dat[, 37])

# group index for X variables
v.group <- as.factor(c(1,1,2,0,1,6,3,1,3,5,5,5,5,5,3,6,6,
                       6,6,6,7,7,7,2,5,8,8,4,4,4,0,0,0,0,0))

gr_lasso_piq<- grpreg(x_piq, y_piq, v.group, penalty="grLasso")
plot(gr_lasso_piq)
```

MODEL -PIQ
```{r, echo=FALSE, fig.height=10, fig.width=10, dpi=300}
cv_lasso_piq <- cv.grpreg(x_piq, y_piq, v.group, 
                        penalty = "grLasso", seed = 123,
                        n.lambda = 200, max.iter = 20000)


#Find the lambda that results in the smallest CV error
best_lasso_piq <- cv_lasso_piq$lambda.min

#Fit model with cross-validated lambda
fit_lasso_piq <- grpreg(x, y, v.group, penalty = "grLasso", lambda = best_lasso_piq)

#Look at coefficients from model with best lambda
fit_lasso_piq$beta

##prediction and MSE using train dataset
grlasso.pred_piq <-  predict(fit_lasso_piq, x)
grlasso_MSE_piq <-  mean((grlasso.pred_piq - y)^2)
grlasso_MSE_piq

lasso_beta_piq <- as_tibble(fit_lasso_piq$beta, rownames = "variable") %>% 
  rename(beta = 2) %>% 
  filter(variable != "(Intercept)") %>% 
  mutate(group3 = v.group,method = "Grouped Lasso")

#Filter out covariates
lasso_beta_piq |> 
  filter(v.group %in% c("1", "2", "3", "4", "5",
                        "6", "7", "8")) |>  
  ggplot(aes(x = variable, y = round(beta, 5))) + 
  geom_point() + theme_minimal() + geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~ group3, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + coord_flip() + 
  labs(title = "Lasso Coefficients for 8 Group Model\nWith lambda values extracted from 10-fold cross-validation\nOutcome: WPPSI-PIQ",
       y = "Beta Coefficient", x = "Variable")
```
